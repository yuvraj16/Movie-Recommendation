{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommending top 10 Movies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperartion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Datasets\n",
    "\n",
    "ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "movies = pd.read_csv('ml-latest-small/movies.csv')\n",
    "tags = pd.read_csv('ml-latest-small/tags.csv')\n",
    "links =  pd.read_csv('ml-latest-small/links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., 21., 11.,  ...,  0.,  0.,  0.],\n",
       "        [21.,  0.,  5.,  ...,  0.,  0.,  0.],\n",
       "        [11.,  5.,  0.,  ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classifying user as 1 who rated move >=4 otherwise 0\n",
    "ratings['Like']=np.where(ratings['rating']>=4,1,0)\n",
    "\n",
    "#Dropping rating column\n",
    "ratings = ratings.drop(['rating'],axis=1) \n",
    "\n",
    "# creating a pivot using userId and movieId of ratings table\n",
    "ratings_pivot = ratings.pivot(index = 'userId', columns ='movieId', values = 'Like').fillna(0)\n",
    "\n",
    "#creating a co-occurence matrix , Each entry Xi,j is the number of users who like both movie i and j\n",
    "rating_co_occ = ratings_pivot.T.dot(ratings_pivot)\n",
    "\n",
    "# converting rating_co_occ to matrix with diagonal elements as 0 so that movie does not compare to itself\n",
    "actual_reco=rating_co_occ.as_matrix()\n",
    "np.fill_diagonal(actual_reco, 0)\n",
    "\n",
    "# converting matrix to tensor using torch\n",
    "\n",
    "actual_reco = torch.from_numpy(rating_co_occ.as_matrix()).float()\n",
    "actual_reco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Matrix to check actual recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>grumpier old men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 9728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId     1     2     3    4    5     6    7    8    9        ...         \\\n",
       "0        1   0.0  21.0  11.0  0.0  7.0  27.0  7.0  1.0  4.0        ...          \n",
       "1        2  21.0   0.0   5.0  0.0  4.0   8.0  6.0  0.0  0.0        ...          \n",
       "2        3  11.0   5.0   0.0  0.0  4.0   4.0  5.0  1.0  2.0        ...          \n",
       "\n",
       "   193573  193579  193581  193583  193585  193587  193609  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "                     title                                       genres  \\\n",
       "0         Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "1           Jumanji (1995)                   Adventure|Children|Fantasy   \n",
       "2  Grumpier Old Men (1995)                               Comedy|Romance   \n",
       "\n",
       "              movie  \n",
       "0         toy story  \n",
       "1           jumanji  \n",
       "2  grumpier old men  \n",
       "\n",
       "[3 rows x 9728 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a reference table with movieId, indexes of movies, movie name and genre\n",
    "# We will use dataframe to compare actually highest rated movies for a given movie with \n",
    "# the movies recommended by the model. (Used in End)\n",
    "\n",
    "reference = rating_co_occ.reset_index()\n",
    "reference = reference.merge(movies_ds, on='movieId', how='inner')\n",
    "reference[\"movie\"]=reference[\"title\"].str.split('(',expand=True)[0].str.strip().str.lower()\n",
    "reference.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoded Movie Matrix For Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# creating a One Hot Encoded matrix for each movie\n",
    "# We will use this matrix to train movie Embeddings \n",
    "\n",
    "#Select uniue movies for which rating is given\n",
    "data = reference[\"movieId\"].unique()\n",
    "values = array(data)\n",
    "\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "#print(onehot_encoded)\n",
    "\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Converting One Hot Encoded Matrix into Tensor to use with as input in Pytorch Module\n",
    "movies_tensor = torch.from_numpy(onehot_encoded).float()\n",
    "movies_tensor= torch.tensor(movies_tensor)\n",
    "print(movies_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model to train Movie Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0  Loss: 63482980.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-5087a56324e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Backward pass: compute gradient of the loss with respect to model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Calling the step function on an Optimizer makes an update to its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "D_in,H, D_out = 9724, 300, 9724\n",
    "\n",
    "# We will store loss after every iteration\n",
    "loss_array =[]\n",
    "\n",
    "# Create X and Y Tensors to hold inputs and outputs\n",
    "x = movies_tensor\n",
    "y = actual_reco\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "\n",
    "\n",
    "model = torch.nn.Linear(D_in, H,bias=0)\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Using ADAM as choice of Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(201):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    v_i = model(x)\n",
    "    v_j = v_i.t()\n",
    "    y_pred = torch.mm(v_i,v_j)\n",
    "\n",
    "    # Setting Diagonals of predicted score matrix to zero\n",
    "    ind = np.diag_indices(y_pred.shape[0])\n",
    "    y_pred[ind[0], ind[1]] = torch.zeros(y_pred.shape[0])\n",
    "    y_pred\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 20 == 0:\n",
    "        print(\"iteration:\",t, \" Loss:\",loss.item())\n",
    "        loss_array.append(loss)\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss of cost function after 200 iterations is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of loss vs interations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Loss vs iteration plot\")\n",
    "plt.plot(loss_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending top 10 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prediction function to give movie recommendations from Model\n",
    "\n",
    "def prediction(moviename):\n",
    "    \n",
    "    #getting tensor for movie\n",
    "    moviename= moviename.lower()\n",
    "    idx = reference[reference[\"movie\"]== moviename].index[0]   \n",
    "    movie = movies_tensor[idx]\n",
    "    movie = movie.reshape(1,movie.shape[0])\n",
    "    \n",
    "    #storing weight vector from model\n",
    "    for name, param in model.named_parameters():\n",
    "        weight_vector = param\n",
    "    \n",
    "    # prediction for given movie\n",
    "    movie_i = model(movie)\n",
    "    pred = torch.mm(movie_i,weight_vector)\n",
    "    \n",
    "    # movie index value sorted from min to max for predicted score values\n",
    "    \n",
    "    pred_idx = (-np.asanyarray(pred[0].detach().numpy())).argsort()[:10]\n",
    "    \n",
    "    # Getting title of recommended movie from Reference Dataframe\n",
    "    recommendations = reference[\"title\"].iloc[pred_idx]\n",
    "    \n",
    "    return recommendations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to see top 10 movies recommendation for a movie in Xij matrix\n",
    "\n",
    "def observed_reco(moviename):\n",
    "    \n",
    "    # Getting Index of Movie from MovieId\n",
    "    idx = reference[reference[\"movie\"]== moviename].index[0]\n",
    "    \n",
    "    # Sorting top 10 movie indexes from Co-Occurence Matrix\n",
    "    obs_idx = (-np.asanyarray(rating_co_occ.iloc[idx])).argsort()[:10]\n",
    "    \n",
    "    # Getting movie title from top 10 movie indexes\n",
    "    recommendations = reference[\"title\"].iloc[obs_idx]\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 movie prediction for Apollo 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model Predictions for apollo 13'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "314                          Forrest Gump (1994)\n",
       "277             Shawshank Redemption, The (1994)\n",
       "257                          Pulp Fiction (1994)\n",
       "510             Silence of the Lambs, The (1991)\n",
       "123                             Apollo 13 (1995)\n",
       "97                             Braveheart (1995)\n",
       "418                         Jurassic Park (1993)\n",
       "398                         Fugitive, The (1993)\n",
       "461                      Schindler's List (1993)\n",
       "224    Star Wars: Episode IV - A New Hope (1977)\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Actual Predictions for apollo 13'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "277             Shawshank Redemption, The (1994)\n",
       "314                          Forrest Gump (1994)\n",
       "257                          Pulp Fiction (1994)\n",
       "418                         Jurassic Park (1993)\n",
       "510             Silence of the Lambs, The (1991)\n",
       "398                         Fugitive, The (1993)\n",
       "97                             Braveheart (1995)\n",
       "461                      Schindler's List (1993)\n",
       "507            Terminator 2: Judgment Day (1991)\n",
       "224    Star Wars: Episode IV - A New Hope (1977)\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie = \"apollo 13\"\n",
    "predicted = prediction(movie)\n",
    "observed = observed_reco(movie)\n",
    "display(\"Model Predictions for \"+str(movie),predicted,\"Actual Predictions for \"+str(movie), observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 movie recommendations for Toy Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model Predictions for toy story'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "277                      Shawshank Redemption, The (1994)\n",
       "314                                   Forrest Gump (1994)\n",
       "257                                   Pulp Fiction (1994)\n",
       "510                      Silence of the Lambs, The (1991)\n",
       "224             Star Wars: Episode IV - A New Hope (1977)\n",
       "1938                                   Matrix, The (1999)\n",
       "897     Star Wars: Episode V - The Empire Strikes Back...\n",
       "899     Raiders of the Lost Ark (Indiana Jones and the...\n",
       "0                                        Toy Story (1995)\n",
       "910     Star Wars: Episode VI - Return of the Jedi (1983)\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Actual Predictions for toy story'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "277                      Shawshank Redemption, The (1994)\n",
       "314                                   Forrest Gump (1994)\n",
       "224             Star Wars: Episode IV - A New Hope (1977)\n",
       "257                                   Pulp Fiction (1994)\n",
       "510                      Silence of the Lambs, The (1991)\n",
       "897     Star Wars: Episode V - The Empire Strikes Back...\n",
       "1938                                   Matrix, The (1999)\n",
       "418                                  Jurassic Park (1993)\n",
       "899     Raiders of the Lost Ark (Indiana Jones and the...\n",
       "910     Star Wars: Episode VI - Return of the Jedi (1983)\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie = \"toy story\"\n",
    "predicted = prediction(movie)\n",
    "observed = observed_reco(movie)\n",
    "display(\"Model Predictions for \"+str(movie),predicted,\"Actual Predictions for \"+str(movie), observed)\n",
    "\n",
    "#display(\"Model Predictions:\",prediction(\"toy story\"),\"Actual Predictions:\", observed_reco(\"toy story\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 movie predictions for Home Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model Predictions for home alone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "314                                   Forrest Gump (1994)\n",
       "504                                     Home Alone (1990)\n",
       "418                                  Jurassic Park (1993)\n",
       "506                                        Aladdin (1992)\n",
       "277                      Shawshank Redemption, The (1994)\n",
       "322                                 Lion King, The (1994)\n",
       "1938                                   Matrix, The (1999)\n",
       "224             Star Wars: Episode IV - A New Hope (1977)\n",
       "0                                        Toy Story (1995)\n",
       "897     Star Wars: Episode V - The Empire Strikes Back...\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Actual Predictions for home alone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "314                   Forrest Gump (1994)\n",
       "418                  Jurassic Park (1993)\n",
       "277      Shawshank Redemption, The (1994)\n",
       "506                        Aladdin (1992)\n",
       "322                 Lion King, The (1994)\n",
       "507     Terminator 2: Judgment Day (1991)\n",
       "0                        Toy Story (1995)\n",
       "510      Silence of the Lambs, The (1991)\n",
       "1938                   Matrix, The (1999)\n",
       "257                   Pulp Fiction (1994)\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie = \"home alone\"\n",
    "predicted = prediction(movie)\n",
    "observed = observed_reco(movie)\n",
    "display(\"Model Predictions for \"+str(movie),predicted,\"Actual Predictions for \"+str(movie), observed)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
